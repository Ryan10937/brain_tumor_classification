{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ef4cd4-4c57-4ac1-bcb3-cc66a1d9590e",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea19e4f-26eb-4a04-ae5f-7a96c3738898",
   "metadata": {},
   "source": [
    "## Steps\n",
    "  \n",
    "1). Use old medical imaging powerpoints and assignments to generate todos for this project\n",
    "\n",
    "2). Find a dataset on Kaggle that satisfies the same (very small if irrc) dataset qualties we used for that project\n",
    "\n",
    "https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\n",
    "\n",
    "3). Apply preprocessing\n",
    "\n",
    "4). Implement U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d461a2-dee7-4c28-a872-011a5e327cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c649b9-eb66-4384-825c-b84929e1cb15",
   "metadata": {},
   "source": [
    "## Load dataset paths/labels into a 2 column df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f0ef49-8e3c-4805-9d66-fa0e632778f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "def gather_dataset(path):\n",
    "  label_dict = {'glioma':0,'meningioma':1,'notumor':2,'pituitary':3}\n",
    "  path_list = [[os.path.join(path,folder,item),label_dict[folder]] for folder in os.listdir(path) for item in os.listdir(os.path.join(path,folder))]\n",
    "  path_df = pd.DataFrame(path_list,columns=['image_path','label'])\n",
    "  return path_df\n",
    "    \n",
    "train_df = gather_dataset('C:/Link_to_D_drive/datasets/Brain_Tumor_MRI/cleaned/Training/')\n",
    "test_df = gather_dataset('C:/Link_to_D_drive/datasets/Brain_Tumor_MRI/cleaned/Testing/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91b8bdd-2d91-4615-9bfd-0353f895a924",
   "metadata": {},
   "source": [
    "## Split data into folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faaad0f1-c775-4c89-aa72-4ca27677890d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#temporarily wait on this?\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec6433a-003d-4006-bdb9-ed072c676931",
   "metadata": {},
   "source": [
    "## Preprocess Images\n",
    "print 3 images with the preprocessing function you make\n",
    "\n",
    "There are some images that dont fit the mold. Like partial-heads. I wonder if i can filter these from the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ea7293-e8b8-4780-b3da-d0b9d9099eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_image(image_path,label):\n",
    "  image = tf.io.read_file(image_path)\n",
    "  image = tf.image.decode_image(image)\n",
    "\n",
    "  one_hot_label = tf.one_hot(label, depth=4)\n",
    "  return image,one_hot_label\n",
    "\n",
    "def get_dataset(df,display=False):\n",
    "  from PIL import Image\n",
    "  import matplotlib.pyplot as plt\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((df['image_path'].to_list(), df['label'].to_list()))\n",
    "  dataset = dataset.map(load_image)\n",
    "  # dataset = dataset.shuffle(buffer_size=1000)\n",
    "  dataset = dataset.batch(batch_size=4)  \n",
    "  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  \n",
    "\n",
    "  if display:\n",
    "    iterator = iter(dataset)\n",
    "    image= next(iterator)[0]\n",
    "    image_np = image.numpy()\n",
    "    for i in range(1,5):\n",
    "      plt.imshow(image_np[i])\n",
    "      plt.show()\n",
    "    \n",
    "  return dataset\n",
    "\n",
    "train_dataset = get_dataset(train_df)\n",
    "val_dataset = get_dataset(val_df)\n",
    "test_dataset = get_dataset(test_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d1544-5d14-4fd7-b696-454a175829d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0aecde0b-52c7-496c-8e3c-07bd61fbbd31",
   "metadata": {},
   "source": [
    "## Train on ImageNet as benchmark, try and do better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e2fabf5-ade2-49fe-88de-e2efecaab0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1071/1071 [==============================] - 32s 26ms/step - loss: 0.4342 - accuracy: 0.8462 - val_loss: 0.3143 - val_accuracy: 0.8768\n",
      "Epoch 2/100\n",
      "1071/1071 [==============================] - 23s 22ms/step - loss: 0.2334 - accuracy: 0.9143 - val_loss: 0.3104 - val_accuracy: 0.8810\n",
      "Epoch 3/100\n",
      "1071/1071 [==============================] - 23s 21ms/step - loss: 0.1850 - accuracy: 0.9316 - val_loss: 0.3029 - val_accuracy: 0.8908\n",
      "Epoch 4/100\n",
      "1071/1071 [==============================] - 23s 21ms/step - loss: 0.1512 - accuracy: 0.9449 - val_loss: 0.2855 - val_accuracy: 0.8985\n",
      "Epoch 5/100\n",
      "1071/1071 [==============================] - 23s 22ms/step - loss: 0.1319 - accuracy: 0.9531 - val_loss: 0.2845 - val_accuracy: 0.9104\n",
      "Epoch 6/100\n",
      "1071/1071 [==============================] - 23s 22ms/step - loss: 0.1173 - accuracy: 0.9545 - val_loss: 0.3144 - val_accuracy: 0.9062\n",
      "Epoch 7/100\n",
      "1071/1071 [==============================] - 34s 32ms/step - loss: 0.1032 - accuracy: 0.9634 - val_loss: 0.2674 - val_accuracy: 0.9083\n",
      "Epoch 8/100\n",
      "1071/1071 [==============================] - 26s 24ms/step - loss: 0.1012 - accuracy: 0.9655 - val_loss: 0.3529 - val_accuracy: 0.8971\n",
      "Epoch 9/100\n",
      "1071/1071 [==============================] - 25s 24ms/step - loss: 0.0833 - accuracy: 0.9704 - val_loss: 0.6643 - val_accuracy: 0.8613\n",
      "Epoch 10/100\n",
      "1071/1071 [==============================] - 26s 24ms/step - loss: 0.0669 - accuracy: 0.9743 - val_loss: 0.5095 - val_accuracy: 0.8746\n",
      "Epoch 11/100\n",
      "1071/1071 [==============================] - 29s 27ms/step - loss: 0.0621 - accuracy: 0.9736 - val_loss: 0.2658 - val_accuracy: 0.9321\n",
      "Epoch 12/100\n",
      "1071/1071 [==============================] - 29s 27ms/step - loss: 0.0694 - accuracy: 0.9729 - val_loss: 0.2656 - val_accuracy: 0.9412\n",
      "Epoch 13/100\n",
      "1071/1071 [==============================] - 30s 28ms/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 0.2430 - val_accuracy: 0.9349\n",
      "Epoch 14/100\n",
      "1071/1071 [==============================] - 33s 31ms/step - loss: 0.0312 - accuracy: 0.9893 - val_loss: 0.2162 - val_accuracy: 0.9454\n",
      "Epoch 15/100\n",
      "1071/1071 [==============================] - 34s 32ms/step - loss: 0.0467 - accuracy: 0.9832 - val_loss: 0.2755 - val_accuracy: 0.9272\n",
      "Epoch 16/100\n",
      "1071/1071 [==============================] - 32s 30ms/step - loss: 0.0352 - accuracy: 0.9858 - val_loss: 0.2466 - val_accuracy: 0.9482\n",
      "Epoch 17/100\n",
      "1071/1071 [==============================] - 35s 32ms/step - loss: 0.0456 - accuracy: 0.9837 - val_loss: 0.5695 - val_accuracy: 0.8943\n",
      "Epoch 18/100\n",
      "1071/1071 [==============================] - 28s 26ms/step - loss: 0.0393 - accuracy: 0.9858 - val_loss: 0.3701 - val_accuracy: 0.9286\n",
      "Epoch 19/100\n",
      "1071/1071 [==============================] - 28s 26ms/step - loss: 0.0452 - accuracy: 0.9844 - val_loss: 0.3120 - val_accuracy: 0.9489\n",
      "Epoch 20/100\n",
      "1071/1071 [==============================] - 28s 26ms/step - loss: 0.0279 - accuracy: 0.9914 - val_loss: 0.3890 - val_accuracy: 0.9265\n",
      "Epoch 21/100\n",
      "1071/1071 [==============================] - 28s 26ms/step - loss: 0.0234 - accuracy: 0.9911 - val_loss: 0.3006 - val_accuracy: 0.9370\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "num_classes=4\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7)\n",
    "# Load the pre-trained ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Freeze the weights of the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add your own classification head\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on your dataset\n",
    "train_summary = model.fit(train_dataset, validation_data=val_dataset,callbacks=[early_stopping], epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be6212-ae5e-441d-952e-07583c2ecbc1",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a31623-c071-4e64-a883-e98d290fefc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 6s 19ms/step - loss: 0.2670 - accuracy: 0.9428\n"
     ]
    }
   ],
   "source": [
    "summary = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc44d0d0-c779-457c-8f1f-ed5a21a64c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2669782340526581, 0.942791759967804]\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a18066-2137-4539-8ba9-3249119b5664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 6s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "def get_image(element, label):\n",
    "  return element\n",
    "def get_label(element, label):\n",
    "  return label\n",
    "test_dataset_images = test_dataset.map(get_image)\n",
    "test_dataset_label = test_dataset.map(get_label)\n",
    "\n",
    "pred = model.predict(test_dataset_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de950f74-dc94-4978-879c-5d1862ccac41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[282,  16,   0,   2],\n",
       "       [ 31, 262,   7,   6],\n",
       "       [  0,   0, 405,   0],\n",
       "       [  4,   9,   0, 287]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "# confusion_matrix([np.argmax(y.numpy()) for x in test_dataset for y in x[1]],[np.argmax(x) for x in pred]) #random confusion matrix, predicionts are in the wrong order\n",
    "\n",
    "\n",
    "original_labels_list = []\n",
    "for label in test_dataset_label:\n",
    "# for label in reversed(list(test_dataset_label)):\n",
    "  for item in label:\n",
    "  # for item in reversed(list(label)):\n",
    "    original_labels_list.append(np.argmax(item.numpy()))\n",
    "new_pred = [np.argmax(x) for x in pred]\n",
    "confusion_matrix(original_labels_list,new_pred) #random confusion matrix, predictions are in the wrong order\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dad43e17-51db-43ca-9491-c64737ab5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add results to original dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086f7b1-dc65-45e6-a4ca-304dc0f1f309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "430d8bc1-a54e-4b7c-a5eb-87abdec63431",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display 3 images from groups of correctly classified records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a31ae2-9029-4678-b999-9fd01778c012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95521640-bf91-4194-90ef-ecb3a795b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display 3 images groups of incorrectly classified records"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
